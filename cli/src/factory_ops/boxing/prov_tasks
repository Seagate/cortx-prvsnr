#!/bin/sh
# Functions in this file address following:
#   1. Stop rabbitmq cluster, if running
#   2. Ref: Stop and restart a RabbitMQ cluster, RMQ clustering 
#   3. Ensure Lnet service is stopped 
#   4. Collect system-wide support bundle using CSM CLI interface
#   5. Backup files 
#       a. /etc/multipath/bindings 
#       b. /etc/multipath.conf 
#   6. Unmount /var/mero and SWAP? (This should be ideally taken care of by OS shutdown)
#   7. Cleanup /tmp 
#   8. Create unboxing user.
#   9. Create boxing flag file on primary node:
#       /opt/seagate/eos-prvsnr/generated_config/boxed
#       Creating file on only one node ensures that the unboxing is executed only on primary node.
set -euE

export LOG_FILE="${LOG_FILE:-/var/log/seagate/provisioner/boxing_prov_tasks.log}"
mkdir -p $(dirname "${LOG_FILE}")
truncate -s 0 ${LOG_FILE}

PRVSNR_ROOT="/opt/seagate/eos-prvsnr"
salt_opts="--no-color --out-file=${LOG_FILE} --out-file-append"
subscription_enabled=false

export pvt_ip_a="${pvt_ip_a:-"192.168.0.1"}"
export pvt_ip_b="${pvt_ip_b:-"192.168.0.2"}"
pvt_ips=("${pvt_ip_a}" "${pvt_ip_b}")
server_names=("Server A" "Server B")
export ssh_cmd="ssh -q -o ConnectTimeout=5 -o PreferredAuthentications=publickey -o StrictHostKeyChecking=no -i /root/.ssh/id_rsa_prvsnr"

function trap_handler {
    echo "***** ERROR! *****"
    echo "For detailed error logs, please see: $LOG_FILE"
    echo "******************"
}
trap trap_handler ERR

function stop_rabbitmq_cluster {
    echo -n "INFO: Removing RabbitMQ from both nodes....." | tee -a ${LOG_FILE}

    salt "*" state.apply components.misc_pkgs.rabbitmq.teardown ${salt_opts} || (
        echo -e "\nERROR: Remove RabbitMQ from both nodes failed." | tee -a ${LOG_FILE}
    ) && ( echo "Done" | tee -a ${LOG_FILE} )
}

function stop_services {
    echo "INFO: Stop LNET from both nodes if active." | tee -a ${LOG_FILE}

    echo "INFO: Stopping lnet on both nodes" | tee -a ${LOG_FILE}
    salt "*" service.stop lnet ${salt_opts} || (echo "ERROR: Failed to stop LNET from both nodes." | tee -a ${LOG_FILE})

    echo "INFO: Stopped LNET from both nodes if active." | tee -a ${LOG_FILE}
}

function backup_files {
    echo -n "INFO: Backing up files on both nodes....." | tee -a ${LOG_FILE}

    bkp_file_list=(
        "/etc/multipath/bindings"
        "/etc/multipath.conf"
    )
    for file in "${bkp_file_list[@]}"; do
        cp $file $file.bak
    done

    echo "Done." | tee -a ${LOG_FILE}
}

function create_unboxing_user {
    set -euE
    _create_date=$(date '+%Y-%m-%d')
    _output_file="/root/Lyve_rack_SystemID_${_create_date}.txt"
    _user="cortxub"
    _sceret=

    if [[ -f /opt/seagate/eos-prvsnr/generated_configs/cluster_id ]]; then
        _secret=`cat /opt/seagate/eos-prvsnr/generated_configs/cluster_id | cut -d- -f 5`
    else
        echo "ERROR: Cortx cluster is not configured on this node" | tee -a ${LOG_FILE}
    fi

    id $_user > /dev/null && {
        userdel -r -f $_user
    }
    echo "INFO: Creating user for first time login" | tee -a ${LOG_FILE}
    useradd --base-dir /tmp --inactive 2 --groups wheel --shell /usr/bin/bash --password $(openssl passwd -1 ${_secret}) cortxub
    passwd -e $_user

    ###### Server A #####
    echo -n "INFO: Getting serial numbers and mac addresses for server A.........." | tee -a ${LOG_FILE}
    _serial_a=`dmidecode -t system | grep Serial | cut -d: -f 2`
    _mac_bmc_a=`ipmitool lan print | grep "MAC Address" | awk '{ print $4 }'`
    #_interface_mgmt_a=`ip -o link show | awk -F': ' '{print $2}' | grep eno1`
    _interface_mgmt_a="eno1"
    _mac_mgmt_a=`cat /sys/class/net/${_interface_mgmt_a}/address`
    _interface_data_a=`ip -o link show | awk -F': ' '{print $2}' | grep enp | grep f0`
    _mac_data_a=`cat /sys/class/net/${_interface_data_a}/address`
    echo "Done" | tee -a ${LOG_FILE}

    ###### Server B #####
    echo -n "INFO: Getting serial numbers and mac addresses for server B.........." | tee -a ${LOG_FILE}
    _serial_b=`ssh srvnode-2 "dmidecode -t system" | grep Serial | cut -d: -f 2`
    _mac_bmc_b=`ssh srvnode-2 "ipmitool lan print" | grep 'MAC Address' | awk '{ print $4 }'`    
    #_interface_mgmt_b=`ssh srvnode-2 "ip -o link show" | awk -F': ' '{print $2}' | grep eno1`
    _interface_mgmt_b="eno1"
    _mac_mgmt_b=`ssh srvnode-2 "cat /sys/class/net/${_interface_mgmt_b}/address"`
    _interface_data_b=`ssh srvnode-2 "ip -o link show" | awk -F': ' '{print $2}' | grep enp | grep f0`
    _mac_data_b=`ssh srvnode-2 "cat /sys/class/net/${_interface_data_b}/address"`
    echo "Done" | tee -a ${LOG_FILE}

    echo "\
**************************************************
NOTE: Store following information for unboxing.
**************************************************" 2>&1 | tee -a ${LOG_FILE}

    cat <<EOL > ${_output_file}
**************************************************
*             Lyve Drive Rack                    *
**************************************************
*         Lyve Drive Rack System ID              *
*------------------------------------------------* 
*                                                *
*                                                *
*                                                *
**************************************************


**************************************************
*    CORTX credentials for initial setup         *
-------------------------------------------------*
  user     : $_user
  password : $_secret

  NOTE: Password expires on first login.    

**************************************************


**************************************************
*                 Server A                       *
*------------------------------------------------*
  Serial Number            : $_serial_a           
  Management Interface MAC : $_mac_mgmt_a
  BMC Interface MAC        : $_mac_bmc_a
  Data Interface MAC       : $_mac_data_a

**************************************************


**************************************************
*                 Server B                       *
*------------------------------------------------*
  Serial Number            : $_serial_b
  Management Interface MAC : $_mac_mgmt_b
  BMC Interface MAC        : $_mac_bmc_b
  Data Interface MAC       : $_mac_data_b

**************************************************
EOL
    cat ${_output_file} 2>&1 | tee -a ${LOG_FILE}

    echo -e "\n\
NOTE: The above system details are required for unboxing and is stored at: $_output_file
      Please replace SystemID with actual System ID in the file name before shipping." | tee -a ${LOG_FILE}

    echo -e "\nThe cluster nodes are going to shutdown now, please copy the above details\n" | tee -a ${LOG_FILE}

    while true; do
        read -p "Have you copied the above details?" _ans
        case $_ans in
            [Yy]* ) break;;
            [Nn]* ) echo "Please copy and press y to proceed..."; continue;;
            * ) echo "Please answer y or n.";;
        esac
    done
}


function reset_pub_data_ips {
    #Reset IPs for public data network
    #Update public data interface ips
    local _cluster_sls_path=${PRVSNR_ROOT}/pillar/components/cluster.sls
    if [[ -f "${PRVSNR_ROOT}/pillar/user/groups/all/cluster.sls" ]]; then
        _cluster_sls_path=${PRVSNR_ROOT}/pillar/user/groups/all/cluster.sls
    fi

    echo "Removing the static IPs of public data network from pillar file for both servers" |tee -a ${LOG_FILE}
    echo "Removing static data ip from $_cluster_sls_path for server A" >> $LOG_FILE
    line_node1_ip=`grep -A8 -n "data_nw:"  $_cluster_sls_path | grep "ipaddr:" | cut -d- -f1 | head -1`
    sed -ie "${line_node1_ip}s/.*/                ipaddr:/" $_cluster_sls_path
    echo "Removing static data ip from $_cluster_sls_path for server B" >> $LOG_FILE
    line_node2_ip=`grep -A8 -n "data_nw:"  $_cluster_sls_path | grep "ipaddr:" | cut -d- -f1 | tail -1`
    sed -ie "${line_node2_ip}s/.*/                ipaddr:/" $_cluster_sls_path
    echo "Done" | tee -a ${LOG_FILE}

    echo "INFO: Resetting the IPs of public data network interface on both nodes." | tee -a ${LOG_FILE}
    salt '*' state.apply components.system.network.data.direct ${salt_opts}
    echo "Done." | tee -a ${LOG_FILE}
}

function boxing_flag {
    #Flag file is created only on primary node,
    # as this helps to ensure unboxing is executed only on primary node.
    echo -n "INFO: Creating flag file on primary node....." | tee -a ${LOG_FILE}

    local file_name=${1:-/opt/seagate/cortx/provisioner/generated_config/boxed}

    if [ ! -f $file_name ]
    then
        timestamp=$(date "+%Y.%m.%d-%H.%M.%S")
        mkdir -p $(dirname "$file_name")
        echo $timestamp > $file_name
    fi

    echo "Done." | tee -a ${LOG_FILE}
}

sub_manager_check()
{
    _pvt_ip="${1:-$pvt_ip_a}"
    _server="${2:-"Server A"}"

    $ssh_cmd $_pvt_ip "grep -qE \"Red Hat\" /etc/*-release" || {
        echo "$_server is not a RedHat system" | tee -a ${LOG_FILE}
        subscription_enabled=false
        return
    }

    echo "Checking if Red Hat subscription is enabled on ${_server}" | tee -a ${LOG_FILE}
    subc_list=`$ssh_cmd $_pvt_ip "subscription-manager list" | grep Status: | awk '{ print $2 }'`
    subc_status=`$ssh_cmd $_pvt_ip "subscription-manager status" | grep "Overall Status:" | awk '{ print $3 }'`
    if echo "$subc_list" | grep -q "Subscribed"; then
        if [[  "$subc_status" == "Current" ]]; then
            echo "RedHat subscription is enabled on ${_server}." | tee -a ${LOG_FILE}
            subscription_enabled=true
        else
            echo "RedHat subscription is disabled on ${_server}." | tee -a ${LOG_FILE}
            subscription_enabled=false
        fi
    fi
}

sub_manager_cleanup()
{
    _pvt_ip="${1:-$pvt_ip_a}"
    _server=${2:-"Server A"}

    $ssh_cmd $_pvt_ip "grep -qE \"Red Hat\" /etc/*-release" || {
        echo "${_server} is not a RedHat system" | tee -a ${LOG_FILE}
        return
    }
    echo "Removing the Red Hat subscription from ${_server}" | tee -a ${LOG_FILE}

    echo "DEBUG: Running the subscription-manager list on ${_server}" >> ${LOG_FILE}
    $ssh_cmd $_pvt_ip "subscription-manager list || true"  | tee -a ${LOG_FILE}

    echo "DEBUG: Running the subscription-manager auto-attach on ${_server}" >> ${LOG_FILE}
    $ssh_cmd $_pvt_ip "subscription-manager auto-attach --disable || true"  | tee -a ${LOG_FILE}

    echo "DEBUG: Running subscription-manager remove --all on ${_server}" >> ${LOG_FILE}
    $ssh_cmd $_pvt_ip "subscription-manager remove --all || true" | tee -a ${LOG_FILE}

    echo "DEBUG: Running subscription-manager unregister on ${_server}" >> ${LOG_FILE}
    $ssh_cmd $_pvt_ip "subscription-manager unregister || true" | tee -a ${LOG_FILE}

    echo "DEBUG: Running subscription-manager clean on ${_server}" >> ${LOG_FILE}
    $ssh_cmd $_pvt_ip "subscription-manager clean || true" | tee -a ${LOG_FILE}

    echo "DEBUG: Running subscription-manager config --rhsm.manage_repos=0 on ${_server}" >> ${LOG_FILE}
    $ssh_cmd $_pvt_ip "subscription-manager config --rhsm.manage_repos=0" | tee -a ${LOG_FILE}
    echo "Done." | tee -a ${LOG_FILE}
}

seagate_refs_cleanup()
{
    # 1. Check if subscription manager is enabled
    # 2. Disable and cleanup the subscription
    # 3. Remove all Seagate internal repos from /etc/yum.repos.d

    for i in "${!pvt_ips[@]}"; do
        subscription_enabled=false
        sub_manager_check "${pvt_ips[$i]}" "${server_names[$i]}"
        if [[ "$subscription_enabled" == true ]]; then
            sub_manager_cleanup "${pvt_ips[$i]}" "${server_names[$i]}"
        fi

        echo "Removing the repos with Seagate URL from Server A" | tee -a ${LOG_FILE}
        mkdir -p /opt/seagate/eos-prvsnr/generated_configs/repos_boxing
        for file in `grep -lE "seagate|salt" /etc/yum.repos.d/*.repo`; do\
            echo "Removing $file";\
            yes | mv -f "$file /opt/seagate/eos-prvsnr/generated_configs/repos_boxing" ;\
        done  >> ${LOG_FILE}

        for file in `grep -lE "baseurl=None" /etc/yum.repos.d/*.repo`; do\
            echo "Removing $file";\
            yes | mv -f "$file /opt/seagate/eos-prvsnr/generated_configs/repos_boxing" ;\
        done  >> ${LOG_FILE}

        echo "Cleaning yum cache on ${server_names[$i]}" | tee -a ${LOG_FILE}
        yum clean all || true  >> ${LOG_FILE}
        echo "Done." | tee -a ${LOG_FILE}

        echo "Removing the repos with Seagate URL from Server B" | tee -a ${LOG_FILE}
        $ssh_cmd ${pvt_ips[$i]} 'mkdir -p /opt/seagate/eos-prvsnr/generated_configs/repos_boxing'
        $ssh_cmd ${pvt_ips[$i]} 'for file in `grep -lE "seagate|salt" /etc/yum.repos.d/*.repo`;\
                                do\
                                 echo "Removing repo: $file";\
                                 yes | mv -f "$file" /opt/seagate/eos-prvsnr/generated_configs/repos_boxing;\
                                done'  >> ${LOG_FILE}
        $ssh_cmd ${pvt_ips[$i]} 'for file in `grep -lE "baseurl=None" /etc/yum.repos.d/*.repo`;\
                                do\
                                 echo "Removing repo: $file";\
                                 yes | mv -f "$file" /opt/seagate/eos-prvsnr/generated_configs/repos_boxing;\
                                done'  >> ${LOG_FILE}
        $ssh_cmd ${pvt_ips[$i]} "yum clean all || true"  >> ${LOG_FILE}

        echo "Done." | tee -a ${LOG_FILE}
        echo "Cleaning yum cache on ${server_names[$i]}" | tee -a ${LOG_FILE}
        $ssh_cmd ${pvt_ips[$i]} "yum clean all || true" >> ${LOG_FILE}
        echo "Done." | tee -a ${LOG_FILE}
    done
}