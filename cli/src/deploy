#!/bin/bash
#
# Copyright (c) 2020 Seagate Technology LLC and/or its Affiliates
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.
# For any questions about this software or licensing,
# please email opensource@seagate.com or cortx-questions@seagate.com.
#

set -euE

BASEDIR=$(dirname "${BASH_SOURCE}")

LOG_FILE="${LOG_FILE:-/var/log/seagate/provisioner/deploy.log}"
export LOG_FILE

. $BASEDIR/common_utils/functions.sh

l_info "***** Running $0 *****"

function trap_handler {
    echo "***** FAILED!! *****"
    echo "For detailed error logs, please see: $LOG_FILE"
}
trap trap_handler ERR

run_all=true
run_system_states=false
run_prereq_states=false
run_sync_states=false
run_io_states=false
run_ha_states=false
run_ctrlpath_states=false
run_backup_states=false
tgt_node=srvnode-2

# states to be applied in desired sequence
system_states=(
    "system"
    "system.storage.multipath"
    #"system.storage.teardown"
    "system.storage"
    "system.network"
    "system.network.data.public"
    "system.network.data.direct"
    "misc_pkgs.rsyslog"
    "system.firewall"
    "system.logrotate"
    "system.chrony"
)

# states to be applied in desired sequence
prereq_states=(
    "misc_pkgs.sos"
    "misc_pkgs.ipmi.bmc_watchdog"
    "misc_pkgs.ssl_certs"
    "ha.haproxy"
    "misc_pkgs.openldap"
    "misc_pkgs.rabbitmq"
    "misc_pkgs.nodejs"
    "misc_pkgs.elasticsearch"
    "misc_pkgs.kibana"
    "misc_pkgs.statsd"
    "misc_pkgs.consul.install"
)

# states to be applied in desired sequence
sync_states=(
    "sync.software.openldap"
    "sync.software.rabbitmq"
)

# states to be applied in desired sequence
iopath_states=(
    "misc_pkgs.lustre"
    "motr"
    "s3server"
)

# states to be applied in desired sequence
ha_states=(
    "ha.corosync-pacemaker"
    "ha.haproxy.start"
    "hare"
    "ha.cortx-ha"
    "ha.iostack-ha"
)

# states to be applied in desired sequence
controlpath_states=(
    "sspl"
    "uds"
    "csm"
    "ha.ctrlstack-ha"
    "ha.cortx-ha.ha"
)

# states to be applied in desired sequence
backup_states=(
    "provisioner.backup"
    "motr.backup"
    "s3server.backup"
    "hare.backup"
    "ha.iostack-ha.backup"
    "sspl.backup"
    "csm.backup"
)

function usage {
  echo "\
Usage: $0 [options]

Installs CORTX stack and configures cortx services either on remote host or locally.

Target host is considered to be an cortx salt-master.

General options:
$base_options_usage
Options:
    -S <tgt_node>,  --singlenode=<tgt_node>      switch to single node mode setup
    --system-states                              deploy only system states
    --prereq-states                              deploy only prereq states (misc_pkgs)
    --sync-states                                deploy only the software synchronization
    --iopath-states                              deploy only iopath states (motr, s3server & Hare)
    --ha-states                                  deploy only ha states (corosync-pacemaker, iostack-ha)
    --ctrlpath-states                            deploy only control path states (sspl & csm)
    --backup-states                              deploy only backup states
"
}


function options_parser {
    set -eu

    case "$1" in
        -S|--singlenode)
            singlenode=true
            tgt_node="$2"
            shift
            ;;
        --system-states)
            run_system_states=true
            run_all=false
            ;;
        --prereq-states)
            run_prereq_states=true
            run_all=false
            ;;
        --sync-states)
            run_sync_states=true
            run_all=false
            ;;
        --iopath-states)
            run_io_states=true
            run_all=false
            ;;
        --ha-states)
            run_ha_states=true
            run_all=false
            ;;
        --ctrlpath-states)
            run_ctrlpath_states=true
            run_all=false
            ;;
        --backup-states)
            run_backup_states=true
            run_all=false
            ;;
        *)
            l_error "Unknown option: $1"
            usage
            exit 5
    esac
}

function is_conul_running {
    count=1
    while [[ /usr/bin/true ]]; do
        l_info "Validating availability of hare-consul-agents on nodes."
        l_info "Attempting every 10 secs..."

        consul_service=$(salt "*" service.status hare-consul-agent-c* --output=json)
        hca1=$(echo ${consul_service}|jq .[\"srvnode-1\"][\"hare-consul-agent-c1\"]|grep -v null)
        hca2=$(echo ${consul_service}|jq .[\"srvnode-2\"][\"hare-consul-agent-c2\"]|grep -v null)
        
        if [[ true == ${hca1} 
            && true == ${hca2}
            ]]; then
            l_info "Both consul agents found running on respective nodes."
            break
        fi

        sleep 10
        count=$((count + 1))

        # Attempt for 5 mins before giving up
        if [[ ${count} > 30 ]]; then
            l_error "Unable to get healthy hare-consul-agent service."
            l_error "Use command 'pcs status' to further find/analyse the issue."
            l_error "Aborting further deployment..."
            exit 1
        fi
    done
}

function run_states {
    local states=${@}

    # apply states
    if [[ "$singlenode" == true ]]; then
        # TODO use salt orchestration
        for state in ${states[@]}; do
            l_info "Applying '$state' on node: $tgt_node"
            $cmd salt "$tgt_node" state.apply $state $salt_opts
            sleep 2     # Mindfulness break
        done
    else
        for state in ${states[@]}; do
            if [[ "$state" == "ha.corosync-pacemaker" ]]; then
                # Execute first on srvnode-2 then on srvnode-1.
                
                l_info "Applying 'ha.corosync-pacemaker.install' for both nodes"
                $cmd salt srvnode-[1,2] state.apply ha.corosync-pacemaker.install  $salt_opts
                sleep 2     # Mindfulness break
                
                l_info "Applying 'ha.corosync-pacemaker.config.base' for both nodes"
                $cmd salt srvnode-[1,2] state.apply ha.corosync-pacemaker.config.base  $salt_opts
                
                l_info "Applying 'ha.corosync-pacemaker.config.authorize' for srvnode-1"
                $cmd salt srvnode-1 state.apply ha.corosync-pacemaker.config.authorize  $salt_opts
                l_info "Applying 'ha.corosync-pacemaker.config.setup_cluster' for srvnode-1"
                $cmd salt srvnode-1 state.apply ha.corosync-pacemaker.config.setup_cluster  $salt_opts
                l_info "Applying 'ha.corosync-pacemaker.config.cluster_ip' for srvnode-1"
                $cmd salt srvnode-1 state.apply ha.corosync-pacemaker.config.cluster_ip  $salt_opts
                l_info "Applying 'ha.corosync-pacemaker.config.stonith' for srvnode-1"
                $cmd salt srvnode-1 state.apply ha.corosync-pacemaker.config.stonith  $salt_opts
            elif [[  "$state" == "system.storage"
                || "$state" == "sspl"
                || "$state" == "csm"
                || "$state" == "provisioner.backup"
                ]]; then

                # Consul takes time to come online after initialization (around 2-3 mins at times)
                # We need to ensure consul service is available before proceeding
                # Without a healthy consul service SSPL and CSM shall fail
                if [[ "$state" == "sspl" ]]; then
                    is_conul_running
                fi

                # Execute first on srvnode-2 then on srvnode-1.
                l_info "Applying '$state' for srvnode-2"
                $cmd salt srvnode-2 state.apply $state  $salt_opts
                sleep 2     # Mindfulness break
                l_info "Applying '$state' for srvnode-1"
                $cmd salt srvnode-1 state.apply $state  $salt_opts
                sleep 2     # Mindfulness break

            elif [[ "$state" == "sync.software.rabbitmq"
                || "$state" == "sync.software.openldap"
                || "$state" == "system.storage.multipath"
                || "$state" == "sync.files"
                ]]; then
                
                # Execute first on srvnode-1 then on srvnode-2.
                l_info "Applying '$state' for srvnode-1"
                $cmd salt srvnode-1 state.apply $state  $salt_opts
                sleep 2     # Mindfulness break
                l_info "Applying '$state' for srvnode-2"
                $cmd salt srvnode-2 state.apply $state  $salt_opts
                sleep 2     # Mindfulness break

            else
                l_info "Applying '$state' for both nodes"
                $cmd salt srvnode-[1,2] state.apply $state $salt_opts
                sleep 2     # Mindfulness break

                # Consul takes time to come online after initialization (around 2-3 mins at times)
                # We need to ensure consul service is available before proceeding
                # Without a healthy consul service SSPL and CSM shall fail
                if [[ "$state" == "ha.iostack-ha" ]]; then
                    is_conul_running
                fi
            fi
        done
    fi
}

function update_salt {
    # Refresh salt pillar data
    l_info "Updating Salt data"
    l_info "Syncing states"
    $cmd salt "*" saltutil.sync_all $salt_opts
    sleep 2
    l_info "Refreshing pillars"
    sleep 2
    $cmd salt "*" saltutil.refresh_pillar $salt_opts
    l_info "Refreshing grains"
    sleep 2
    $cmd salt "*" saltutil.refresh_grains $salt_opts
    sleep 2
}

function encrypt_pillar {
    # Encrypt passwords in pillar data
    l_info "Encrypting salt pillar data"
    python3 ${BASEDIR}/pillar_encrypt
    update_salt
}


parse_args 'S' 'singlenode:,prereq-states,sync-states,iopath-states,ha-states,ctrlpath-states,system-states,backup-states' options_parser '' "$@"

if [[ "$verbosity" -ge 2 ]]; then
    set -x
fi

cmd="$(build_command "$hostspec" "$ssh_config" "$sudo" 2>/dev/null)"

salt_opts=
salt_opts_dry_run=
if [[ "$dry_run" == true ]]; then
    salt_opts_dry_run="test=True"
fi
salt_opts="--no-color --out-file=$LOG_FILE --out-file-append $salt_opts_dry_run --timeout=600"

update_salt

if [[ "$run_all" == true ]]; then
    salt "*" cmd.run "rescan-scsi-bus.sh || true" $salt_opts
    run_states "${system_states[@]}"
    run_states "${prereq_states[@]}"
    run_states  "${sync_states[@]}"
    run_states  "${iopath_states[@]}"
    run_states "${ha_states[@]}"

    # l_info "Sleeping for 5 mins for hare-hax to stabilize..." 
    # sleep 300

    run_states "${controlpath_states[@]}"
    run_states "${backup_states[@]}"
fi

if [[ "$run_system_states" == true ]]; then
    l_info "Deploying the system states"
    salt "*" cmd.run "rescan-scsi-bus.sh || true" $salt_opts
    run_states "${system_states[@]}"
fi

if [[ "$run_prereq_states" == true ]]; then
    l_info "Deploying the prereq states"
    run_states  "${prereq_states[@]}"
fi

if [[ "$run_sync_states" == true ]]; then
    l_info "Deploying the sync states"
    run_states  "${sync_states[@]}"
fi

# if [[ "$run_io_states" == true || "$run_ha_states" == true ]]; then
#     l_info "Recreating the metadata partitions"
#     salt 'srvnode-2' state.apply system.storage $salt_opts
#     salt 'srvnode-1' state.apply system.storage $salt_opts
# fi

if [[ "$run_io_states" == true ]]; then
    l_info "Deploying the io path states"
    run_states  "${iopath_states[@]}"
fi

if [[ "$run_ha_states" == true ]]; then
    l_info "Deploying the ha states"
    run_states "${ha_states[@]}"
fi

if [[ "$run_ctrlpath_states" == true ]]; then
    
    # l_info "Sleeping for 5 mins for hare-hax to stabilize..." 
    # sleep 300

    l_info "Deploying the control path states"
    run_states "${controlpath_states[@]}"
fi

if [[ "$run_backup_states" == true ]]; then
    l_info "Synchronizing files on both nodes."
    run_states "${backup_states[@]}"
fi

# l_info "Backing up pillar files to user space."
# mkdir -p /opt/seagate/cortx/provisioner/pillar/user/groups/all
# cp -r /opt/seagate/cortx/provisioner/pillar/components/*.sls /opt/seagate/cortx/provisioner/pillar/user/groups/all/
# chown -R :prvsnrusers /opt/seagate/cortx/provisioner/pillar/user
# chmod -R 664 /opt/seagate/cortx/provisioner/pillar/user/groups/all/*.sls

l_info "***** SUCCESS! *****"
l_info "The detailed logs can be seen at: $LOG_FILE"
l_info "Done"

