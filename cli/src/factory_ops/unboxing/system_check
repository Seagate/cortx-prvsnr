#!/bin/sh
#
# Copyright (c) 2020 Seagate Technology LLC and/or its Affiliates
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.
# For any questions about this software or licensing,
# please email opensource@seagate.com or cortx-questions@seagate.com.
#



# Functions in this file address following:
#   1. Check boxing flag file and proceed only if boxing.<timestamp> file is present
#       /opt/seagate/cortx_configs/provisioner_generated/boxing.<timestamp>
#   2. Check if IP is available on management network interface on node. Wait till one is obtained.
#   3. Check if hostname is available on node. Wait till one is obtained.
#   4. Ping across nodes over direct network to check connectivity and fetch peer hostname. Wait till success.
#       From node-1
#       $ ping -c1 -I<public_data_ip> srvnode-2
#       From node-2
#       $ ping -c1 -I<public_data_ip> srvnode-1
# NOTE: pick value of public_data_ip from cluster.sls
set -euE

export LOG_FILE="${LOG_FILE:-/var/log/seagate/provisioner/unboxing_system_check.log}"
mkdir -p $(dirname "${LOG_FILE}")
#truncate -s 0 ${LOG_FILE}

BASEDIR=$(dirname "${BASH_SOURCE}")

. ${BASEDIR}/../../common_utils/utility_scripts.sh

export PRVSNR_ROOT="/opt/seagate/cortx/provisioner"

cluster_sls_path="${pillar_root}/uu_cluster.sls"

function trap_handler {
    echo "***** ERROR! *****"
    echo "For detailed error logs, please see: $LOG_FILE"
    echo "******************"
}
trap trap_handler ERR

function check_boxing_flag {
    if [[ -f '/opt/seagate/cortx_configs/provisioner_generated/boxed' ]]
    then
        echo "DEBUG: Boxed file found." >> ${LOG_FILE}
    else
        echo "\
ERROR: Boxing command was not run
       Please ensure that the boxing sequence was run successfully before running unboxing.
***** FAILED!! *****" | tee -a ${LOG_FILE}
        exit 1
    fi
}

function check_salt_services {
    # Check salt-master running on primary node.
    if ! systemctl status salt-master>/dev/null; then
        systemctl start salt-master
    fi

    # Check salt-minion on primary node.
    if ! systemctl status salt-master>/dev/null; then
        systemctl start salt-minion
    fi

    if ! ($ssh_cmd ${pvt_ip_b} "systemctl status salt-master>/dev/null"); then
        $ssh_cmd ${pvt_ip_b} "systemctl start salt-minion"
    fi
}

function check_hostname {
    echo -n "      Hostname (Server A)      : " |tee -a ${LOG_FILE}
    hostname 2>&1|tee -a ${LOG_FILE}

    echo -n "      Hostname (Server B)      : " |tee -a ${LOG_FILE}
    ssh -i /root/.ssh/id_rsa_prvsnr -o "StrictHostKeyChecking no" ${pvt_ip_b} "hostname" 2>&1|tee -a ${LOG_FILE}
}

function check_pvt_data_connectivity {
    # local private_data_if=$(grep -m1 -A5 -P "data:" ${cluster_sls_path}|grep -A2 "interfaces:"|tail -1|cut -d'-' -f2|tr -d "[:space:]")

    echo "      Private n/w IP (Server A): $pvt_ip_a" | tee -a ${LOG_FILE}
    echo "      Private n/w IP (Server B): $pvt_ip_b" | tee -a ${LOG_FILE}
    
    # node1 => node2: private data interface
    echo -n "Checking connectivity from server A to server B over private network........" | tee -a ${LOG_FILE}
    ping -c1 -W2 -I${pvt_ip_a} ${pvt_ip_b} > /dev/null || (echo "ERROR: Unable to ping srvnode-2 from srvnode-1, over ${private_data_if}" |tee -a ${LOG_FILE}; exit 1)
    echo "Ok." | tee -a ${LOG_FILE}

    echo -n "Checking connectivity from server B to server A over private network........" | tee -a ${LOG_FILE}
    # node2 => node1: private data interface
    ssh -i /root/.ssh/id_rsa_prvsnr -o ConnectTimeout=5 -o "StrictHostKeyChecking no" ${pvt_ip_b} "ping -c1 -W2 -I${pvt_ip_b} ${pvt_ip_a}" > /dev/null || (echo "ERROR: Unable to ping srvnode-1 from srvnode-2, over ${private_data_if}" |tee -a ${LOG_FILE}; exit 1)
    echo "Ok." | tee -a ${LOG_FILE}
}

function check_mgmt_ip {
    # Although ways to test public data IP are available;
    # Only management IP would be tested as public data IP would be later updated during onboarding.

    local mgmt_if=$(grep -m1 -A3 -P "mgmt:" ${cluster_sls_path}|grep -A1 "interfaces:"|tail -1|cut -d'-' -f2|tr -d "[:space:]")
    if [[ -z "$mgmt_if" ]]; then
        if ip -o addr | grep -q eno1; then
            mgmt_if="eno1"
        else
            echo "ERROR: Could not get the management interface" | tee -a ${LOG_FILE}
            exit 1
        fi
    fi

    # Node-1 IPs
    # ip for mgmt interface
    local mgmt_ip_1=$((ip addr show dev ${mgmt_if}|grep inet|grep -v inet6|grep -Po "\d{1,3}.\d{1,3}.\d{1,3}.\d{1,3}" || echo "ERROR: IP address missing for ${mgmt_if} on srvnode-1" || (tee -a ${LOG_FILE}; exit 1))|head -1)
    echo "      Management IP (Server A) : ${mgmt_ip_1}" | tee -a ${LOG_FILE}


    # Node-2 IPs
    # ip for mgmt interface
    local mgmt_ip_2=$(($ssh_cmd ${pvt_ip_b} "ip addr show dev ${mgmt_if}|grep inet|grep -v inet6|grep -Po \"\d{1,3}.\d{1,3}.\d{1,3}.\d{1,3}\"" || (echo "ERROR: IP address missing for ${mgmt_if} on srvnode-2" | tee -a ${LOG_FILE}; echo 1))|head -1)
    echo "      Management IP (Server B) : ${mgmt_ip_2}" | tee -a ${LOG_FILE}

    # ip for public data interface
    # local public_data_ip_2=$(ssh -i /root/.ssh/id_rsa_prvsnr -o "StrictHostKeyChecking no" ${pvt_ip_b} "ip addr show dev ${public_data_if}|grep inet|grep -v inet6|grep -Po \"\d{1,3}.\d{1,3}.\d{1,3}.\d{1,3}\"|head -1")
    # echo ${public_data_ip_2}

    # Start ping test
    # node1 => node2: mgmt interface
    # node1 => node2: private data interface
    echo -n "Checking connectivity from server A to server B over management network....." | tee -a ${LOG_FILE}
    ping -c1 -W2 -I${mgmt_if} ${mgmt_ip_2} > /dev/null || (echo "ERROR: Unable to ping srvnode-2 from srvnode-1, over ${mgmt_if}" |tee -a ${LOG_FILE}; exit 1)
    echo "Ok." | tee -a ${LOG_FILE}

    # node2 => node1: private data interface
    echo -n "Checking connectivity from server B to server A over management network....." | tee -a ${LOG_FILE}
    ssh -i /root/.ssh/id_rsa_prvsnr -o ConnectTimeout=5 -o "StrictHostKeyChecking no" ${pvt_ip_b} "ping -c1 -W2 -I${mgmt_if} ${mgmt_ip_1}" > /dev/null || (echo "ERROR: Unable to ping srvnode-1 from srvnode-2, over ${mgmt_if}" |tee -a ${LOG_FILE}; exit 1)
    echo "Ok." | tee -a ${LOG_FILE}
}

#   prvsnr_check <check>
#   e.g. prvsnr_check hostnames
#
#   Performs provisioner check
#
#   Prerequisites:
#       - The provisioner repo is installed.
#
#   Args:
#       check: check to be performed. The checks are listed in Checks class
#              in api/python/provisioner/config.py
function prvsnr_check {
    # Execute 'provisioner check' cli command with mentioned check
    local prvsnr_chk_cmd="provisioner check $1"
    # Perform the check and get the output. Check for any failures.
    local fail_msg=$(${prvsnr_chk_cmd} | grep "fail")

    # If no failures, check is successful. Else display the failure message
    if [ -z "${fail_msg}" ]
    then
        echo "Ok." | tee -a ${LOG_FILE}
    else
        echo -n "ERROR: Command '${prvsnr_chk_cmd}' Failed. " | tee -a ${LOG_FILE}
        echo ${fail_msg} | tee -a ${LOG_FILE}
        exit 1
    fi
}

function check_public_data_interfaces {
    echo -n "Checking if IP addresses for public data interfaces are set........" | tee -a ${LOG_FILE}
    prvsnr_check public_data_ip
}

function check_bmc_accessibility {
    echo -n "Checking BMC accessibility from both servers........" | tee -a ${LOG_FILE}
    prvsnr_check bmc_accessibility
}

function check_controller_ip {
    echo -n "Checking Server-A and Server-B can access (ping) Controller-A and Controller-B on the enclosure........" | tee -a ${LOG_FILE}
    prvsnr_check controller_ip
}
